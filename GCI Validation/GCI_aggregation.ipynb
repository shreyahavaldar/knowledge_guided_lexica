{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from googletrans import Translator\n",
    "import sqlalchemy\n",
    "from tqdm import tqdm, trange\n",
    "from scipy.stats.stats import pearsonr, spearmanr  \n",
    "from scipy.stats import zscore\n",
    "import random\n",
    "import pingouin as pg\n",
    "import math\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in relevant files/MySQL tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyah/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/shreyah/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  \n",
      "/home/shreyah/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/shreyah/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/shreyah/.conda/envs/shreya_env/lib/python3.6/site-packages/outdated/utils.py:18: OutdatedCacheFailedWarning: Failed to use cache while checking for outdated package.\n",
      "Set the environment variable OUTDATED_RAISE_EXCEPTION=1 for a full traceback.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  **kwargs\n",
      "/home/shreyah/.conda/envs/shreya_env/lib/python3.6/site-packages/outdated/utils.py:18: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.3.12, the latest is 0.5.3.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  **kwargs\n"
     ]
    }
   ],
   "source": [
    "db_twitter = sqlalchemy.engine.url.URL(drivername='mysql', host='127.0.0.1', database='twitterSuperUsers', query={'read_default_file': '~/.my.cnf', 'charset':'utf8mb4'})\n",
    "db_lexica = sqlalchemy.engine.url.URL(drivername='mysql', host='127.0.0.1', database='dlatk_lexica', query={'read_default_file': '~/.my.cnf', 'charset':'utf8'})\n",
    "db_county = sqlalchemy.engine.url.URL(drivername='mysql', host='127.0.0.1', database='county_data', query={'read_default_file': '~/.my.cnf', 'charset':'utf8'})\n",
    "db_project = sqlalchemy.engine.url.URL(drivername='mysql', host='127.0.0.1', database='individualism_collectivism', query={'read_default_file': '~/.my.cnf', 'charset':'utf8'})\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_project)\n",
    "# county_scores = pd.read_sql(\"feat$cat_individVsCollectFinal$msgs_100u$cnty$1gra\", con=engine)\n",
    "# state_scores = pd.read_sql(\"feat$cat_individVsCollectFinal$msgs_100u$state$1gra\", con=engine)\n",
    "\n",
    "county_scores = pd.read_sql(\"feat$cat_individVsCollect_w$msgs_100u$cnty$1gra\", con=engine)\n",
    "state_scores = pd.read_sql(\"feat$cat_individVsCollect_w$msgs_100u$state$1gra\", con=engine)\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_lexica)\n",
    "lexicon = pd.read_sql(\"individVsCollectFinal\", con=engine)\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_county)\n",
    "county_mapping = pd.read_sql(\"county_by_state_reg_div\", con=engine)\n",
    "community_mapping = pd.read_sql(\"superCrossWalk_FINAL_FINAL\", con=engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go from county name --> fips code\n",
    "def name_to_county(name):\n",
    "    #get state name\n",
    "    state = name.split(\",\")[-1].strip()\n",
    "    if(state == \"Puerto Rico\"): \n",
    "        return None\n",
    "    #get county name\n",
    "    county = (name.split(\",\")[0]).split(\"County\")[0].strip()\n",
    "    county = county.split(\"Municipality\")[0].strip()\n",
    "    county = county.split(\"Borough\")[0].strip()\n",
    "    county = county.split(\"Parish\")[0].strip()\n",
    "    county = county.replace(\"city\", \"City\")\n",
    "    county = county.replace(\"ñ\", \"n\")\n",
    "   \n",
    "    temp = county_mapping[county_mapping[\"state\"] == state]\n",
    "    temp = temp[temp[\"county\"] == county][\"cnty\"]\n",
    "    try:\n",
    "        return np.array(temp)[0]\n",
    "    except:\n",
    "        print(\"Couldn't map to fips code: \", name)\n",
    "        return None\n",
    "\n",
    "#calculate correlation between two county-level data points\n",
    "def calculate_correlation(data1, data2):\n",
    "    overlapping_keys = np.intersect1d(list(data1.keys()), list(data2.keys()))\n",
    "    values1 = [data1[x] for x in overlapping_keys]\n",
    "    values2 = [data2[x] for x in overlapping_keys]\n",
    "    return pearsonr(values1, values2)\n",
    "\n",
    "def get_county_map():\n",
    "    mapping = {}\n",
    "    with open(\"GCI Data/counties.txt\") as f:\n",
    "        lines = [line.rstrip() for line in f]\n",
    "        for l in lines:\n",
    "            parts = l.split(\",\")\n",
    "            mapping[parts[1]] = int(parts[0])\n",
    "    return mapping\n",
    "\n",
    "#get state-aggregated data for county-level data (average over all counties)\n",
    "def get_state_data(county_data):\n",
    "    mapping = get_county_map()\n",
    "    state_data = {}\n",
    "    for c in county_data:\n",
    "        try:\n",
    "            state = list((county_mapping[county_mapping[\"cnty\"] == c])[\"state\"])[0]\n",
    "        except:\n",
    "            continue\n",
    "        if state not in state_data.keys():\n",
    "            state_data[state] = []\n",
    "        state_data[state].append(county_data[c])       \n",
    "    \n",
    "    state_data_final = {}\n",
    "    for s in state_data:\n",
    "        state_data_final[s] = np.average(state_data[s])\n",
    "    return normalize_data(state_data_final)\n",
    "\n",
    "def normalize_data(data):\n",
    "    keys = data.keys()\n",
    "    vals = np.array([data[x] for x in keys])\n",
    "    normalized_vals = zscore(vals) \n",
    "    return dict(zip(keys,normalized_vals))\n",
    "\n",
    "#get correlation between single (list) and (list of lists) at the county level\n",
    "def validate_data(input_data, other_data):\n",
    "    overlapping_keys = list(input_data.keys())\n",
    "    for d in other_data:\n",
    "        overlapping_keys = np.intersect1d(list(d.keys()), overlapping_keys)\n",
    "    \n",
    "    data_values = np.array([input_data[x] for x in overlapping_keys])\n",
    "    other_data_intersect = []\n",
    "    for d in other_data:\n",
    "        other_data_intersect.append(np.array([d[x] for x in overlapping_keys]))   \n",
    "    print(pearsonr(data_values, sum(other_data_intersect)))   \n",
    "\n",
    "def get_overlapping_keys(dicts):\n",
    "    overlapping_keys = list(dicts[0].keys())\n",
    "    for d in dicts:\n",
    "        overlapping_keys = np.intersect1d(list(d.keys()), overlapping_keys)\n",
    "    return overlapping_keys\n",
    "\n",
    "def process_dicts(dicts):\n",
    "    keys = get_overlapping_keys(dicts)\n",
    "    processed_lists = []   \n",
    "    for d in dicts:\n",
    "        processed_list = np.array([d[x] for x in keys])\n",
    "        processed_lists.append(processed_list)\n",
    "    return keys, processed_lists\n",
    "\n",
    "def get_community_mapping():\n",
    "    cnty = community_mapping[\"cnty\"]\n",
    "    ACP_name = community_mapping[\"ACP_name\"]\n",
    "    mappings = {}   \n",
    "    communities = np.array(ACP_name)\n",
    "    communities = np.unique(communities[communities != np.array(None)])\n",
    "    for i in range(len(cnty)):      \n",
    "        mappings[cnty[i]] = ACP_name[i]\n",
    "    return communities, mappings\n",
    "\n",
    "def zero_one_normalize(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't map to fips code:  United States\n"
     ]
    }
   ],
   "source": [
    "income_data = pd.read_csv(\"GCI Data/income_census.csv\")\n",
    "income_data.set_index(\"Label (Grouping)\", inplace=True)\n",
    "income_data = income_data.T\n",
    "\n",
    "income_string = \"Median earnings (dollars) for full-time, year-round workers with earnings\"\n",
    "\n",
    "#remove unecessary data\n",
    "temp_columns = income_data.columns\n",
    "for c in temp_columns:\n",
    "    if (income_string in c):\n",
    "        income_data[\"income\"] = income_data[c]\n",
    "income_data.drop(columns=temp_columns, inplace=True)\n",
    "\n",
    "income_control = {}\n",
    "for index, row in income_data.iterrows():\n",
    "    if(\"Total!!Estimate\" not in index): continue\n",
    "    name = index.split(\"!!\")[0]\n",
    "    fips = name_to_county(name)\n",
    "    if fips is not None:                       \n",
    "        try:\n",
    "            income = int(row[\"income\"].replace(\",\", \"\"))\n",
    "            income_control[fips] = income\n",
    "        except:\n",
    "            continue\n",
    "income_control = normalize_data(income_control)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 1: Fertility Rate\n",
    "\n",
    "##### Total fertility rate for each county, US Census, county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fertility_data = pd.read_csv(\"GCI Data/fertility_census.csv\")\n",
    "# fertility_data.set_index(\"Label (Grouping)\", inplace=True)\n",
    "# rate_string = \"!!Women with births in the past 12 months !!Rate per 1,000 women!!Estimate\"\n",
    "\n",
    "# #remove unecessary data\n",
    "# for c in fertility_data.columns:\n",
    "#     if(rate_string in c):\n",
    "#         name = c.split(rate_string)[0]\n",
    "#         fertility_data[name] = fertility_data[c]\n",
    "#     fertility_data.drop(columns=[c], inplace=True)\n",
    "\n",
    "# fertility_data = fertility_data.T\n",
    "# columns_temp = fertility_data.columns\n",
    "\n",
    "# #keep only relevant columns\n",
    "# fertility_data[\"all\"] = fertility_data[\"Women 15 to 50 years\"]\n",
    "# fertility_data[\"15-19\"] = fertility_data[\"15 to 19 years\"]\n",
    "# fertility_data[\"20-34\"] = fertility_data[\"20 to 34 years\"]\n",
    "# fertility_data[\"35-50\"] = fertility_data[\"35 to 50 years\"]\n",
    "# fertility_data.drop(columns=columns_temp, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tfr(row):\n",
    "#     try:\n",
    "#         return (int(row[\"15-19\"])*5 + int(row[\"20-34\"])*15 + int(row[\"35-50\"])*16)/1000\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "# tfr_data = {}\n",
    "# for index,row in fertility_data.iterrows():\n",
    "#     tfr = get_tfr(row)\n",
    "#     fips = name_to_county(index)\n",
    "#     if(tfr is not None and fips is not None):\n",
    "#         tfr_data[fips] = tfr\n",
    "\n",
    "# tfr_data = normalize_data(tfr_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 2: Living Arrangements\n",
    "\n",
    "##### Number of households with grandparents living with grandchildren, US Census, county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't map to fips code:  United States\n"
     ]
    }
   ],
   "source": [
    "household_data = pd.read_csv(\"GCI Data/household_census.csv\")\n",
    "household_data.set_index(\"Label (Grouping)\", inplace=True)\n",
    "household_data = household_data.T\n",
    "\n",
    "# coll_string = \"Household with grandparents living with grandchildren:\"\n",
    "coll_string = \"Household with grandparent responsible for own grandchildren under 18 years\"\n",
    "other_string = \"Household without grandparents living with grandchildren\"\n",
    "\n",
    "#remove unecessary data\n",
    "temp_columns = household_data.columns\n",
    "temp_columns = temp_columns.drop(\"Total:\")\n",
    "for c in temp_columns:\n",
    "    if (coll_string in c):\n",
    "        household_data[\"total_coll\"] = household_data[c]\n",
    "    elif (other_string in c):\n",
    "        household_data[\"total_other\"] = household_data[c]\n",
    "household_data.drop(columns=temp_columns, inplace=True)\n",
    "\n",
    "living_data = {}\n",
    "for index, row in household_data.iterrows():\n",
    "    name = index.split(\"!!\")[0]\n",
    "    fips = name_to_county(name)\n",
    "    if fips is not None:                       \n",
    "        try:\n",
    "            # total = int(row[\"Total:\"].replace(\",\", \"\"))\n",
    "            total = int(row[\"total_coll\"].replace(\",\", \"\")) + int(row[\"total_other\"].replace(\",\", \"\"))\n",
    "            total_coll = int(row[\"total_coll\"].replace(\",\", \"\"))\n",
    "            living_data[fips] = (total_coll)/total\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "living_data = normalize_data(living_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 3: Stability of Marriage\n",
    "\n",
    "##### Ratio of married individuals to divorced individuals 15 years and over (sum of men and women), US Census, county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marital_data = pd.read_csv(\"GCI Data/divorce_census.csv\")\n",
    "# marital_data.set_index(\"Label (Grouping)\", inplace=True)\n",
    "# marital_data = marital_data.T\n",
    "\n",
    "# total_string_male = \"Males 15 years and over\"\n",
    "# total_string_female = \"Females 15 years and over\"\n",
    "# divorce_string = \"Divorced\"\n",
    "# separated_string = \"Separated\"\n",
    "# married_string = \"Now married, except separated\"\n",
    "\n",
    "# #remove unecessary data\n",
    "# temp_columns = marital_data.columns\n",
    "# for c in temp_columns:\n",
    "#     if(divorce_string in c):\n",
    "#         label = (c.split(\"(\"))[1].split(\")\")[0]\n",
    "#         marital_data[\"num_divorced_\"+label] = marital_data[c]\n",
    "#     elif(married_string in c):\n",
    "#         label = (c.split(\"(\"))[1].split(\")\")[0]\n",
    "#         marital_data[\"num_married_\"+label] = marital_data[c]\n",
    "#     elif(separated_string in c):\n",
    "#         label = (c.split(\"(\"))[1].split(\")\")[0]\n",
    "#         marital_data[\"num_separated_\"+label] = marital_data[c]\n",
    "#     elif(total_string_male in c):\n",
    "#         marital_data[\"total_male\"] = marital_data[c]\n",
    "#     elif(total_string_female in c):\n",
    "#         marital_data[\"total_female\"] = marital_data[c]\n",
    "# marital_data.drop(columns=temp_columns, inplace=True)\n",
    "\n",
    "# marriage_data = {}\n",
    "# for index, row in marital_data.iterrows():\n",
    "#     if(\"Percent\" in index): continue\n",
    "#     name = index.split(\"!!\")[0]\n",
    "#     fips = name_to_county(name)\n",
    "#     if fips is not None:                       \n",
    "#         try:\n",
    "#             married = int(row[\"num_married_male\"].replace(\",\", \"\")) + int(row[\"num_married_female\"].replace(\",\", \"\"))\n",
    "#             divorced = int(row[\"num_divorced_male\"].replace(\",\", \"\")) + int(row[\"num_divorced_female\"].replace(\",\", \"\")) \n",
    "#             separated = int(row[\"num_separated_male\"].replace(\",\", \"\")) + int(row[\"num_separated_female\"].replace(\",\", \"\"))\n",
    "#             total = int(row[\"total_male\"].replace(\",\", \"\")) + int(row[\"total_female\"].replace(\",\", \"\"))\n",
    "#             marriage_data[fips] = married/divorced\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "# marriage_data = normalize_data(marriage_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 4: Religiosity\n",
    "\n",
    "##### Score for question \"For each of the following aspects, indicate how important it is in your life. Would you say it is very important, rather important, not very important or not important at all? – Religion\" (scale of 1-4) \n",
    "##### Inverse weighted so high importance --> high score, WVS Survey, state level\n",
    "##### Standard devation per state = 1.02 --> enforcing that each state must have > 10 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyah/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (345,347,349,574,575,576) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "wvs_data = pd.read_csv(\"GCI Data/WVS_Cross-National_Wave_7.csv\")\n",
    "wvs_data_usa = wvs_data[wvs_data[\"B_COUNTRY_ALPHA\"] == \"USA\"]\n",
    "\n",
    "wvs_state_mapping = {}\n",
    "with open(\"GCI Data/wvs_states.txt\") as f:\n",
    "    lines = [line.rstrip() for line in f]\n",
    "for l in lines:\n",
    "    parts = l.split(\" \")\n",
    "    wvs_state_mapping[int(parts[0])] = \" \".join(parts[3:])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD DEV: 1.0217751798668622\n"
     ]
    }
   ],
   "source": [
    "religion_data_temp = {}\n",
    "\n",
    "for index, row in wvs_data_usa.iterrows():\n",
    "    state = wvs_state_mapping[row[\"N_REGION_WVS\"]]\n",
    "    religious_importance = row[\"Q6\"]\n",
    "    if(religious_importance > 0):\n",
    "        if(state not in religion_data_temp.keys()):\n",
    "            religion_data_temp[state] = []\n",
    "        religion_data_temp[state].append(religious_importance)\n",
    "\n",
    "religion_data = {}\n",
    "std_devs = []\n",
    "for s in religion_data_temp:\n",
    "    if(len(religion_data_temp[s]) > 10):\n",
    "        religion_data[s] = 1/np.average(religion_data_temp[s])\n",
    "    std_devs.append(np.std(religion_data_temp[s]))\n",
    "print(\"STD DEV:\", np.average(std_devs))\n",
    "    \n",
    "religion_data = normalize_data(religion_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 5: Collective Transportation\n",
    "\n",
    "##### Average number of cars per household, inverse weights so high number of cars --> low score, US Census, county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transportation_data = pd.read_csv(\"GCI Data/transportation_census.csv\")\n",
    "# transportation_data.set_index(\"Label (Grouping)\", inplace=True)\n",
    "# transportation_data = transportation_data.T\n",
    "\n",
    "# temp_columns = transportation_data.columns\n",
    "# temp_columns = temp_columns.drop(\"Total:\")\n",
    "# for c in temp_columns:\n",
    "#     col_name = c.strip()\n",
    "#     transportation_data[col_name] = transportation_data[c]\n",
    "# transportation_data.drop(columns=temp_columns, inplace=True)\n",
    "\n",
    "# def get_cars_per_household(row):\n",
    "#     total = int(row[\"Total:\"].replace(\",\", \"\"))\n",
    "#     none = int(row[\"No vehicle available\"].replace(\",\", \"\"))\n",
    "#     car1 = int(row[\"1 vehicle available\"].replace(\",\", \"\"))\n",
    "#     car2 = int(row[\"2 vehicles available\"].replace(\",\", \"\"))\n",
    "#     car3 = int(row[\"3 vehicles available\"].replace(\",\", \"\"))\n",
    "#     car4 = int(row[\"4 or more vehicles available\"].replace(\",\", \"\"))\n",
    "#     return (car1 + car2*2 + car3*3 + car4*4)/total\n",
    "\n",
    "# car_data = {}\n",
    "# for index, row in transportation_data.iterrows():\n",
    "#     name = index.split(\"!!\")[0]\n",
    "#     fips = name_to_county(name)\n",
    "#     if fips is not None:                       \n",
    "#         try:\n",
    "#             car_data[fips] = 1/get_cars_per_household(row)\n",
    "#         except:\n",
    "#             continue\n",
    "# car_data = normalize_data(car_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator 6: Ingroup Bias\n",
    "\n",
    "##### Score for question \"Do you agree, disagree or neither agree nor disagree with the following statements? - When jobs are scarce, employers should give priority to people of this country over immigrants.\" (scale of 1-5) \n",
    "##### Inverse weighted so high agreement --> high score, WVS Survey, state level\n",
    "##### Average standard devation per state = 0.82 --> enforcing each state must have > 5 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STD DEV: 0.8247487844563858\n"
     ]
    }
   ],
   "source": [
    "compatriotism_data_temp = {}\n",
    "\n",
    "for index, row in wvs_data_usa.iterrows():\n",
    "    state = wvs_state_mapping[row[\"N_REGION_WVS\"]]\n",
    "    bias = row[\"Q34\"]\n",
    "    if(bias > 0):\n",
    "        if(state not in compatriotism_data_temp.keys()):\n",
    "            compatriotism_data_temp[state] = []\n",
    "        compatriotism_data_temp[state].append(bias)\n",
    "\n",
    "compatriotism_data = {}\n",
    "std_devs = []\n",
    "for s in compatriotism_data_temp:\n",
    "    compatriotism_data[s] = 1/np.average(compatriotism_data_temp[s]) \n",
    "    std_devs.append(np.std(compatriotism_data_temp[s]))\n",
    "print(\"STD DEV:\", np.average(std_devs))\n",
    "\n",
    "compatriotism_data = normalize_data(compatriotism_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All data at the state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state df shape:  (42, 4)\n",
      "Pairwise Pearson Correlations at the state level (all)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grandparents</th>\n",
       "      <th>income</th>\n",
       "      <th>religion</th>\n",
       "      <th>compatriotism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>grandparents</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.538756</td>\n",
       "      <td>0.549095</td>\n",
       "      <td>0.317850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.538756</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.413523</td>\n",
       "      <td>-0.180937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>0.549095</td>\n",
       "      <td>-0.413523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compatriotism</th>\n",
       "      <td>0.317850</td>\n",
       "      <td>-0.180937</td>\n",
       "      <td>0.749607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               grandparents    income  religion  compatriotism\n",
       "grandparents       1.000000 -0.538756  0.549095       0.317850\n",
       "income            -0.538756  1.000000 -0.413523      -0.180937\n",
       "religion           0.549095 -0.413523  1.000000       0.749607\n",
       "compatriotism      0.317850 -0.180937  0.749607       1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cronbach alpha\n",
      "(0.33480090412993235, array([-0.068,  0.611]))\n"
     ]
    }
   ],
   "source": [
    "# tfr_data_state = get_state_data(tfr_data)\n",
    "living_data_state = get_state_data(living_data)\n",
    "# marriage_data_state = get_state_data(marriage_data)\n",
    "# car_data_state = get_state_data(car_data)\n",
    "income_data_state = get_state_data(income_control)\n",
    "\n",
    "# state_data = [tfr_data_state, living_data_state, marriage_data_state, car_data_state, religion_data, compatriotism_data]\n",
    "state_data = [living_data_state, income_data_state, religion_data, compatriotism_data]\n",
    "# state_labels = [\"fertility\", \"grandparents\", \"marriage\", \"cars\", \"religion\", \"compatriotism\"]\n",
    "state_labels = [\"grandparents\", \"income\", \"religion\", \"compatriotism\"]\n",
    "#make state df\n",
    "fips_codes, state_data_processed = process_dicts(state_data)\n",
    "state_df = pd.DataFrame(columns=state_labels)\n",
    "for i in range(len(state_labels)):\n",
    "    state_df[state_labels[i]] = state_data_processed[i]\n",
    "state_df.set_index(fips_codes, inplace=True)\n",
    "\n",
    "print(\"state df shape: \",  state_df.shape)\n",
    "print(\"Pairwise Pearson Correlations at the state level (all)\")\n",
    "display(state_df.corr())\n",
    "print(\"Cronbach alpha\")\n",
    "print(pg.cronbach_alpha(data=state_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ran experiments with every subset of >3 variables at the state level to maximize Cronbach's Alpha. Result: Include living arrangements, religiosity, and compatriotism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# living_data_state = get_state_data(living_data)\n",
    "# income_data_state = get_state_data(income_control)\n",
    "\n",
    "# state_data = [living_data_state, religion_data, compatriotism_data]\n",
    "# state_labels = [\"grandparents\", \"religion\", \"compatriotism\"]\n",
    "\n",
    "# # state_data = [tfr_data_state, living_data_state, religion_data, compatriotism_data]\n",
    "# # state_labels = [\"fertility\", \"grandparents\", \"religion\", \"compatriotism\"]\n",
    "\n",
    "# #make state df\n",
    "# fips_codes, state_data_processed = process_dicts(state_data)\n",
    "# state_df = pd.DataFrame(columns=state_labels)\n",
    "# for i in range(len(state_labels)):\n",
    "#     state_df[state_labels[i]] = state_data_processed[i]\n",
    "# state_df.set_index(fips_codes, inplace=True)\n",
    "\n",
    "# print(\"state df shape: \",  state_df.shape)\n",
    "# print(\"Pairwise Pearson Correlations at the state level\")\n",
    "# display(state_df.corr())\n",
    "# print(\"Cronbach alpha\")\n",
    "# print(pg.cronbach_alpha(data=state_df))\n",
    "\n",
    "# state_data = [living_data_state, religion_data, compatriotism_data, income_data_state]\n",
    "# state_labels = [\"grandparents\", \"religion\", \"compatriotism\", \"income\"]\n",
    "# #make state df\n",
    "# fips_codes, state_data_processed = process_dicts(state_data)\n",
    "# state_df = pd.DataFrame(columns=state_labels)\n",
    "# for i in range(len(state_labels)):\n",
    "#     state_df[state_labels[i]] = state_data_processed[i]\n",
    "# state_df.set_index(fips_codes, inplace=True)\n",
    "\n",
    "# # print(\"Pairwise Pearson Correlations at the state level (including income)\")\n",
    "# # display(state_df.corr())\n",
    "# state_df.corr().to_csv(\"test.csv\")\n",
    "# print(\"Partial correlations controlling for income\")\n",
    "# display(state_df.pcorr())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Collectivism/Individualism Scores: County level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coll_scores_county = county_scores[county_scores[\"feat\"] == \"COLLECTIVIST\"]\n",
    "# coll_scores_county = dict(zip(coll_scores_county.group_id, coll_scores_county.group_norm))\n",
    "\n",
    "# indv_scores_county = county_scores[county_scores[\"feat\"] == \"INDIVIDUALIST\"]\n",
    "# indv_scores_county = dict(zip(indv_scores_county.group_id, indv_scores_county.group_norm))\n",
    "\n",
    "# county_data=[living_data, marriage_data, car_data, coll_scores_county, indv_scores_county, income_control]\n",
    "# county_labels = [\"fertility\", \"grandparents\", \"marriage\", \"cars\", \"collectivism\", \"individualism\", \"income\"]\n",
    "\n",
    "# #make county df\n",
    "# fips_codes, state_data_processed = process_dicts(county_data)\n",
    "# county_df = pd.DataFrame(columns=county_labels)\n",
    "# for i in range(len(county_labels)):\n",
    "#     county_df[county_labels[i]] = state_data_processed[i]\n",
    "# county_df.set_index(fips_codes, inplace=True)\n",
    "\n",
    "# print(\"county df shape: \", county_df.shape)\n",
    "# print(\"Pairwise Pearson Correlations at the county level (all)\")\n",
    "# display(county_df.corr())\n",
    "# print(\"Cronbach alpha\")\n",
    "# print(pg.cronbach_alpha(data=county_df))\n",
    "\n",
    "# print(len(county_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat$cat_ablation_045_075_w$msgs_100u$cnty$1gra\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.417 & -0.545 & -0.664 & -0.542 & -0.542 \\\\\n",
      "0.275 & 0.171 & 0.175 & 0.314 & 0.234 \\\\\n",
      "0.003 & 0.0 & 0.0 & 0.0 \\\\\n",
      "0.053 & 0.28 & 0.267 & 0.043 \\\\\n",
      "\n",
      "feat$cat_ablation_045_07_w$msgs_100u$cnty$1gra\n",
      "-0.417 & -0.545 & -0.664 & -0.542 & -0.542 \\\\\n",
      "0.226 & 0.113 & 0.124 & 0.274 & 0.184 \\\\\n",
      "0.003 & 0.0 & 0.0 & 0.0 \\\\\n",
      "0.115 & 0.476 & 0.433 & 0.079 \\\\\n",
      "\n",
      "feat$cat_ablation_045_08_w$msgs_100u$cnty$1gra\n",
      "-0.417 & -0.545 & -0.664 & -0.542 & -0.542 \\\\\n",
      "0.263 & 0.168 & 0.167 & 0.305 & 0.226 \\\\\n",
      "0.003 & 0.0 & 0.0 & 0.0 \\\\\n",
      "0.065 & 0.289 & 0.289 & 0.05 \\\\\n",
      "\n",
      "feat$cat_ablation_04_075_w$msgs_100u$cnty$1gra\n",
      "0.095 & 0.512 & 0.446 & 0.308 & 0.34 \\\\\n",
      "0.273 & 0.504 & 0.531 & 0.552 & 0.465 \\\\\n",
      "0.51 & 0.001 & 0.003 & 0.047 \\\\\n",
      "0.055 & 0.001 & 0.0 & 0.0 \\\\\n",
      "\n",
      "feat$cat_ablation_04_07_w$msgs_100u$cnty$1gra\n",
      "0.095 & 0.512 & 0.446 & 0.308 & 0.34 \\\\\n",
      "0.27 & 0.5 & 0.528 & 0.552 & 0.462 \\\\\n",
      "0.51 & 0.001 & 0.003 & 0.047 \\\\\n",
      "0.058 & 0.001 & 0.0 & 0.0 \\\\\n",
      "\n",
      "feat$cat_ablation_04_08_w$msgs_100u$cnty$1gra\n",
      "0.095 & 0.512 & 0.446 & 0.308 & 0.34 \\\\\n",
      "0.271 & 0.505 & 0.531 & 0.552 & 0.465 \\\\\n",
      "0.51 & 0.001 & 0.003 & 0.047 \\\\\n",
      "0.057 & 0.001 & 0.0 & 0.0 \\\\\n",
      "\n",
      "feat$cat_ablation_05_075_w$msgs_100u$cnty$1gra\n",
      "-0.545 & -0.504 & -0.618 & -0.539 & -0.552 \\\\\n",
      "0.029 & -0.184 & -0.26 & -0.057 & -0.118 \\\\\n",
      "0.0 & 0.001 & 0.0 & 0.0 \\\\\n",
      "0.842 & 0.245 & 0.096 & 0.718 \\\\\n",
      "\n",
      "feat$cat_ablation_05_07_w$msgs_100u$cnty$1gra\n",
      "-0.545 & -0.504 & -0.618 & -0.539 & -0.552 \\\\\n",
      "-0.014 & -0.234 & -0.297 & -0.094 & -0.16 \\\\\n",
      "0.0 & 0.001 & 0.0 & 0.0 \\\\\n",
      "0.923 & 0.136 & 0.056 & 0.554 \\\\\n",
      "\n",
      "feat$cat_ablation_05_08_w$msgs_100u$cnty$1gra\n",
      "-0.545 & -0.504 & -0.618 & -0.539 & -0.552 \\\\\n",
      "0.008 & -0.196 & -0.279 & -0.078 & -0.137 \\\\\n",
      "0.0 & 0.001 & 0.0 & 0.0 \\\\\n",
      "0.959 & 0.213 & 0.073 & 0.622 \\\\\n",
      "\n",
      "feat$cat_ablation_1_1_w$msgs_100u$cnty$1gra\n",
      "-0.509 & -0.423 & -0.564 & -0.525 & -0.506 \\\\\n",
      "-0.033 & -0.267 & -0.352 & -0.142 & -0.198 \\\\\n",
      "0.0 & 0.005 & 0.0 & 0.0 \\\\\n",
      "0.818 & 0.088 & 0.022 & 0.371 \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "#Table names\n",
    "# feat$cat_ablation_045_075_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_045_07_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_045_08_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_04_075_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_04_07_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_04_08_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_05_075_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_05_07_w$msgs_100u$cnty$1gra\n",
    "# feat$cat_ablation_05_08_w$msgs_100u$cnty$1gra\n",
    "\n",
    "TABLE_NAMES = [\"feat$cat_ablation_045_075_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_045_07_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_045_08_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_04_075_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_04_07_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_04_08_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_05_075_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_05_07_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_05_08_w$msgs_100u$cnty$1gra\",\n",
    "                \"feat$cat_ablation_1_1_w$msgs_100u$cnty$1gra\"]\n",
    "\n",
    "purification_param = \"indv\"\n",
    "PURIFICATION_NAMES = [\"feat$cat_purification_{}_0_01_w$msgs_100u$cnty$1gra\".format(purification_param),\n",
    "                        \"feat$cat_purification_{}_0_05_w$msgs_100u$cnty$1gra\".format(purification_param),\n",
    "                        \"feat$cat_purification_{}_0_1_w$msgs_100u$cnty$1gra\".format(purification_param),\n",
    "                        \"feat$cat_purification_{}_0_15_w$msgs_100u$cnty$1gra\".format(purification_param),\n",
    "                        \"feat$cat_purification_{}_0_2_w$msgs_100u$cnty$1gra\".format(purification_param),\n",
    "                        \"feat$cat_purification_{}_0_25_w$msgs_100u$cnty$1gra\".format(purification_param)]\n",
    "\n",
    "table_labels = [\"scores_final\", \"scores_seed_only\", \"scores_expansion_only\"]\n",
    "table_names = [\"feat$cat_purification_015_w$msgs_100u$cnty$1gra\", \"feat$cat_ablation_1_1_w$msgs_100u$cnty$1gra\", \"feat$cat_ablation_045_075_w$msgs_100u$cnty$1gra\"]\n",
    "\n",
    "\n",
    "def print_val_data(table_name, label):\n",
    "    engine = sqlalchemy.create_engine(db_project)\n",
    "    county_scores = pd.read_sql(table_name, con=engine)\n",
    "    # county_scores = pd.concat([pd.read_sql(table_name, con=engine), pd.read_sql(table_name.replace(\"indv\", \"coll\"), con=engine)])\n",
    "\n",
    "    # county_scores = pd.read_sql(\"feat$cat_individVsCollect_w$msgs_100u$cnty$1gra\", con=engine)\n",
    "    # state_scores = pd.read_sql(\"feat$cat_individVsCollect_w$msgs_100u$state$1gra\", con=engine)\n",
    "\n",
    "    coll_scores_county = county_scores[county_scores[\"feat\"] == \"COLLECTIVISM\"]\n",
    "    if(len(coll_scores_county) == 0):\n",
    "        coll_scores_county = county_scores[county_scores[\"feat\"] == \"COLLECTIVIST\"]\n",
    "    coll_scores_county = dict(zip(coll_scores_county.group_id, coll_scores_county.group_norm))\n",
    "\n",
    "    indv_scores_county = county_scores[county_scores[\"feat\"] == \"INDIVIDUALISM\"]\n",
    "    if(len(indv_scores_county) == 0):\n",
    "        indv_scores_county = county_scores[county_scores[\"feat\"] == \"INDIVIDUALIST\"]\n",
    "    indv_scores_county = dict(zip(indv_scores_county.group_id, indv_scores_county.group_norm))\n",
    "\n",
    "\n",
    "    coll_scores_state = get_state_data(coll_scores_county)\n",
    "    indv_scores_state = get_state_data(indv_scores_county)\n",
    "    \n",
    "    living_data_state = get_state_data(living_data)\n",
    "    income_data_state = get_state_data(income_control)\n",
    "\n",
    "    state_data = [living_data_state, religion_data, compatriotism_data, income_data_state, coll_scores_state, indv_scores_state]\n",
    "    coll_label = \"{}_coll\".format(label)\n",
    "    indv_label = \"{}_indv\".format(label)\n",
    "    state_labels = [\"grandparents\", \"religion\", \"compatriotism\", \"income\", \"collectivism\", \"individualism\"]\n",
    "\n",
    "    #make state df\n",
    "    states, state_data_processed = process_dicts(state_data)\n",
    "    state_df = pd.DataFrame(columns=state_labels)\n",
    "    for i in range(len(state_labels)):\n",
    "        state_df[state_labels[i]] = zero_one_normalize(state_data_processed[i])\n",
    "    state_df.set_index(states, inplace=True)\n",
    "\n",
    "    def get_corr(col1, col2):\n",
    "        return pearsonr(state_df[col1], state_df[col2])\n",
    "\n",
    "    grandparents_indv =  get_corr(\"individualism\", \"grandparents\")[0]\n",
    "    religion_indv = get_corr(\"individualism\", \"religion\")[0]\n",
    "    compatriotism_indv = get_corr(\"individualism\", \"compatriotism\")[0]\n",
    "    grandparents_coll = get_corr(\"collectivism\", \"grandparents\")[0]\n",
    "    religion_coll = get_corr(\"collectivism\", \"religion\")[0]\n",
    "    compatriotism_coll = get_corr(\"collectivism\", \"compatriotism\")[0]\n",
    "\n",
    "    grandparents_indv_pval = get_corr(\"individualism\", \"grandparents\")[1]\n",
    "    religion_indv_pval = get_corr(\"individualism\", \"religion\")[1]\n",
    "    compatriotism_indv_pval = get_corr(\"individualism\", \"compatriotism\")[1]\n",
    "    grandparents_coll_pval = get_corr(\"collectivism\", \"grandparents\")[1]\n",
    "    religion_coll_pval = get_corr(\"collectivism\", \"religion\")[1]\n",
    "    compatriotism_coll_pval = get_corr(\"collectivism\", \"compatriotism\")[1]\n",
    "\n",
    "    indv_running_average = (get_corr(\"individualism\", \"grandparents\")[0] + \n",
    "                    get_corr(\"individualism\", \"religion\")[0] + \n",
    "                    get_corr(\"individualism\", \"compatriotism\")[0])\n",
    "    \n",
    "    coll_running_average = (get_corr(\"collectivism\", \"grandparents\")[0] +\n",
    "                            get_corr(\"collectivism\", \"religion\")[0] +\n",
    "                            get_corr(\"collectivism\", \"compatriotism\")[0])\n",
    "\n",
    "    vc_scores = pd.read_csv(\"GCI Data/vandello_cohen.csv\")\n",
    "    vc_scores = dict(zip(vc_scores.State, vc_scores.Score))\n",
    "\n",
    "    state_data = [vc_scores, coll_scores_state, indv_scores_state]\n",
    "    state_labels = [\"vandello-cohen\", \"collectivism\", \"individualism\"]\n",
    "\n",
    "    #make state df\n",
    "    states, state_data_processed = process_dicts(state_data)\n",
    "    state_df = pd.DataFrame(columns=state_labels)\n",
    "    for i in range(len(state_labels)):\n",
    "        state_df[state_labels[i]] = zero_one_normalize(state_data_processed[i])\n",
    "    state_df.set_index(states, inplace=True)\n",
    "\n",
    "    indv_vc = get_corr(\"individualism\", \"vandello-cohen\")[0]\n",
    "    coll_vc = get_corr(\"collectivism\", \"vandello-cohen\")[0]\n",
    "\n",
    "    indv_vc_pval = get_corr(\"individualism\", \"vandello-cohen\")[1]\n",
    "    coll_vc_pval = get_corr(\"collectivism\", \"vandello-cohen\")[1]\n",
    "\n",
    "    average_corr_indv = (indv_running_average + get_corr(\"vandello-cohen\", \"individualism\")[0])/4\n",
    "    average_corr_coll = (coll_running_average + get_corr(\"vandello-cohen\", \"collectivism\")[0])/4\n",
    "\n",
    "    #print latex table wither rounding to 3 dec points\n",
    "    #individualism: vc, grandparents, religion, compatriotism\n",
    "    #print correlations, add a * if p < 0.05\n",
    "    def get_string(corr, pval):\n",
    "        if(pval < 0.05): return str(round(corr, 3)) + \"$^*$\"\n",
    "        else: return str(round(corr, 3))\n",
    "    \n",
    "    print(get_string(indv_vc, indv_vc_pval), \"&\", get_string(grandparents_indv, grandparents_indv_pval), \"&\", get_string(religion_indv, religion_indv_pval), \"&\", get_string(compatriotism_indv, compatriotism_indv_pval), \"&\", get_string(average_corr_indv, 0), \"\\\\\\\\\")\n",
    "    print(get_string(coll_vc, coll_vc_pval), \"&\", get_string(grandparents_coll, grandparents_coll_pval), \"&\", get_string(religion_coll, religion_coll_pval), \"&\", get_string(compatriotism_coll, compatriotism_coll_pval), \"&\", get_string(average_corr_coll, 0), \"\\\\\\\\\")\n",
    "\n",
    "for t in TABLE_NAMES:\n",
    "    print(t)\n",
    "    print_val_data(t, t)\n",
    "    print()\n",
    "\n",
    "\n",
    "# state_df_csv = pd.DataFrame()\n",
    "# state_df_vc_csv = pd.DataFrame()\n",
    "# for t,label in zip(table_names, table_labels):  \n",
    "#     state_df, state_df_vc = print_val_data(t, label)\n",
    "#     if(len(state_df_csv) == 0): state_df_csv = state_df.copy()\n",
    "#     if(len(state_df_vc_csv) == 0): state_df_vc_csv = state_df_vc.copy()\n",
    "#     for c in state_df.columns:\n",
    "#         if c not in state_df_csv.columns:\n",
    "#             state_df_csv[c] = state_df[c]\n",
    "#     for c in state_df_vc.columns:\n",
    "#         if c not in state_df_vc_csv.columns:\n",
    "#             state_df_vc_csv[c] = state_df_vc[c]\n",
    "        \n",
    "\n",
    "# state_df_csv.to_csv(\"GCI_validation.csv\")\n",
    "# state_df_vc_csv.to_csv(\"VC_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat$cat_purification_indv_0_01_w$msgs_100u$cnty$1gra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyah/.local/lib/python3.6/site-packages/scipy/stats/stats.py:2497: RuntimeWarning: Mean of empty slice.\n",
      "  mns = a.mean(axis=axis, keepdims=True)\n",
      "/home/shreyah/.local/lib/python3.6/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/home/shreyah/.local/lib/python3.6/site-packages/numpy/core/_methods.py:234: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/home/shreyah/.local/lib/python3.6/site-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/home/shreyah/.local/lib/python3.6/site-packages/numpy/core/_methods.py:224: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-08ec9a272141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPURIFICATION_NAMES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint_val_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-60a3cf0c7348>\u001b[0m in \u001b[0;36mprint_val_data\u001b[0;34m(table_name, label)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mstate_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mstate_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzero_one_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_data_processed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mstate_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5b5ac375bc57>\u001b[0m in \u001b[0;36mzero_one_normalize\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzero_one_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2829\u001b[0m     \"\"\"\n\u001b[1;32m   2830\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0;32m-> 2831\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "for t in PURIFICATION_NAMES:\n",
    "    print(t)\n",
    "    print_val_data(t, t)\n",
    "    print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Collectivism/Individualism Scores: State level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Pearson Correlations at the state level\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grandparents</th>\n",
       "      <th>religion</th>\n",
       "      <th>compatriotism</th>\n",
       "      <th>collectivism</th>\n",
       "      <th>individualism</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>grandparents</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.549095</td>\n",
       "      <td>0.317850</td>\n",
       "      <td>0.361601</td>\n",
       "      <td>-0.570941</td>\n",
       "      <td>-0.538756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>0.549095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749607</td>\n",
       "      <td>0.410151</td>\n",
       "      <td>-0.659027</td>\n",
       "      <td>-0.413523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compatriotism</th>\n",
       "      <td>0.317850</td>\n",
       "      <td>0.749607</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467353</td>\n",
       "      <td>-0.515438</td>\n",
       "      <td>-0.180937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collectivism</th>\n",
       "      <td>0.361601</td>\n",
       "      <td>0.410151</td>\n",
       "      <td>0.467353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.510319</td>\n",
       "      <td>-0.288011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individualism</th>\n",
       "      <td>-0.570941</td>\n",
       "      <td>-0.659027</td>\n",
       "      <td>-0.515438</td>\n",
       "      <td>-0.510319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.538756</td>\n",
       "      <td>-0.413523</td>\n",
       "      <td>-0.180937</td>\n",
       "      <td>-0.288011</td>\n",
       "      <td>0.431243</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               grandparents  religion  compatriotism  collectivism  \\\n",
       "grandparents       1.000000  0.549095       0.317850      0.361601   \n",
       "religion           0.549095  1.000000       0.749607      0.410151   \n",
       "compatriotism      0.317850  0.749607       1.000000      0.467353   \n",
       "collectivism       0.361601  0.410151       0.467353      1.000000   \n",
       "individualism     -0.570941 -0.659027      -0.515438     -0.510319   \n",
       "income            -0.538756 -0.413523      -0.180937     -0.288011   \n",
       "\n",
       "               individualism    income  \n",
       "grandparents       -0.570941 -0.538756  \n",
       "religion           -0.659027 -0.413523  \n",
       "compatriotism      -0.515438 -0.180937  \n",
       "collectivism       -0.510319 -0.288011  \n",
       "individualism       1.000000  0.431243  \n",
       "income              0.431243  1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engine = sqlalchemy.create_engine(db_project)\n",
    "county_scores = pd.read_sql(\"feat$cat_purification_015_w$msgs_100u$cnty$1gra\", con=engine)\n",
    "\n",
    "coll_scores_county = county_scores[county_scores[\"feat\"] == \"COLLECTIVISM\"]\n",
    "if(len(coll_scores_county) == 0):\n",
    "    coll_scores_county = county_scores[county_scores[\"feat\"] == \"COLLECTIVIST\"]\n",
    "coll_scores_county = dict(zip(coll_scores_county.group_id, coll_scores_county.group_norm))\n",
    "\n",
    "indv_scores_county = county_scores[county_scores[\"feat\"] == \"INDIVIDUALISM\"]\n",
    "if(len(indv_scores_county) == 0):\n",
    "    indv_scores_county = county_scores[county_scores[\"feat\"] == \"INDIVIDUALIST\"]\n",
    "indv_scores_county = dict(zip(indv_scores_county.group_id, indv_scores_county.group_norm))\n",
    "\n",
    "coll_scores_state = get_state_data(coll_scores_county)\n",
    "indv_scores_state = get_state_data(indv_scores_county)\n",
    "\n",
    "state_data = [living_data_state, religion_data, compatriotism_data, coll_scores_state, indv_scores_state, income_data_state]\n",
    "state_labels = [\"grandparents\", \"religion\", \"compatriotism\", \"collectivism\", \"individualism\", \"income\"]\n",
    "\n",
    "#make state df\n",
    "states, state_data_processed = process_dicts(state_data)\n",
    "state_df = pd.DataFrame(columns=state_labels)\n",
    "for i in range(len(state_labels)):\n",
    "    state_df[state_labels[i]] = zero_one_normalize(state_data_processed[i])\n",
    "state_df.set_index(states, inplace=True)\n",
    "\n",
    "print(\"Pairwise Pearson Correlations at the state level\")\n",
    "display(state_df.corr())\n",
    "\n",
    "state_df.to_csv(\"validation.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Collectivism/Individualism Scores: Community level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'county_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-91b62534a779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindv_scores_community\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounty_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmappings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfips\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'county_df' is not defined"
     ]
    }
   ],
   "source": [
    "_, mappings = get_community_mapping()\n",
    "\n",
    "coll_scores_community = {}\n",
    "indv_scores_community = {}\n",
    "\n",
    "for fips, row in county_df.iterrows():\n",
    "    try:\n",
    "        c = mappings[fips]\n",
    "        if(c not in coll_scores_community.keys()):\n",
    "            coll_scores_community[c] = []\n",
    "            indv_scores_community[c] = []\n",
    "        coll_scores_community[c].append(coll_scores_county[fips])\n",
    "        indv_scores_community[c].append(indv_scores_county[fips])\n",
    "    except(Exception):\n",
    "        # print(\"Couldn't map to community: \", fips)\n",
    "        continue \n",
    "           \n",
    "communities = list(coll_scores_community.keys())\n",
    "for c in communities:\n",
    "    if(len(coll_scores_community[c]) < 15):\n",
    "        del coll_scores_community[c]\n",
    "        del indv_scores_community[c]\n",
    "    else:\n",
    "        # print(c, \" & \", len(coll_scores_community[c]), \"\\\\\\\\\")\n",
    "        continue\n",
    "\n",
    "community_df = pd.DataFrame()\n",
    "communities = list(coll_scores_community.keys())\n",
    "community_df[\"community\"] = communities\n",
    "community_df[\"collectivism\"] = zero_one_normalize([np.mean(coll_scores_community[x]) for x in communities])\n",
    "community_df[\"individualism\"] = zero_one_normalize([np.mean(indv_scores_community[x]) for x in communities])\n",
    "\n",
    "print(\"most individualistic communities\")\n",
    "print(community_df.sort_values(by=\"individualism\", ascending=False).head(10))\n",
    "\n",
    "community_df.to_csv(\"community_scores.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vandello-Cohen Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Pearson Correlations at the state level\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vandello-cohen</th>\n",
       "      <th>collectivism</th>\n",
       "      <th>individualism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vandello-cohen</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.275331</td>\n",
       "      <td>-0.415244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collectivism</th>\n",
       "      <td>0.275331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individualism</th>\n",
       "      <td>-0.415244</td>\n",
       "      <td>-0.058544</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                vandello-cohen  collectivism  individualism\n",
       "vandello-cohen        1.000000      0.275331      -0.415244\n",
       "collectivism          0.275331      1.000000      -0.058544\n",
       "individualism        -0.415244     -0.058544       1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vc_scores = pd.read_csv(\"GCI Data/vandello_cohen.csv\")\n",
    "vc_scores = dict(zip(vc_scores.State, vc_scores.Score))\n",
    "\n",
    "state_data = [vc_scores, coll_scores_state, indv_scores_state]\n",
    "state_labels = [\"vandello-cohen\", \"collectivism\", \"individualism\"]\n",
    "\n",
    "#make state df\n",
    "states, state_data_processed = process_dicts(state_data)\n",
    "state_df = pd.DataFrame(columns=state_labels)\n",
    "for i in range(len(state_labels)):\n",
    "    state_df[state_labels[i]] = zero_one_normalize(state_data_processed[i])\n",
    "state_df.set_index(states, inplace=True)\n",
    "\n",
    "print(\"Pairwise Pearson Correlations at the state level\")\n",
    "display(state_df.corr())\n",
    "\n",
    "state_df.to_csv(\"vc_scores.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      collectivism  individualism  cnty      diff\n",
      "0         0.000598       0.001533     0 -0.000935\n",
      "1001      0.000960       0.001439  1001 -0.000480\n",
      "1003      0.000984       0.001639  1003 -0.000655\n",
      "1005      0.001183       0.001437  1005 -0.000255\n",
      "1007      0.001014       0.001510  1007 -0.000496\n"
     ]
    }
   ],
   "source": [
    "county_data = [coll_scores_county, indv_scores_county]\n",
    "county_labels = [\"collectivism\", \"individualism\"]\n",
    "\n",
    "#make county df\n",
    "fips_codes, state_data_processed = process_dicts(county_data)\n",
    "county_df = pd.DataFrame(columns=county_labels)\n",
    "for i in range(len(county_labels)):\n",
    "    county_df[county_labels[i]] = (state_data_processed[i])\n",
    "county_df.set_index(fips_codes, inplace=True)\n",
    "county_df[\"cnty\"] = fips_codes\n",
    "# county_df[\"diff\"] = zero_one_normalize(county_df[\"collectivism\"]-county_df[\"individualism\"])\n",
    "county_df[\"diff\"] = county_df[\"collectivism\"]-county_df[\"individualism\"]\n",
    "\n",
    "print(county_df.head())\n",
    "engine = sqlalchemy.create_engine(db_county)\n",
    "county_df.to_sql(\"cnty_coll_indv_outcomes\", con=engine, index=False, if_exists='replace', chunksize=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyah/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134\n"
     ]
    }
   ],
   "source": [
    "db_indv_coll = sqlalchemy.engine.url.URL(drivername='mysql', host='127.0.0.1', database='individualism_collectivism', query={'read_default_file': '~/.my.cnf', 'charset':'utf8'})\n",
    "\n",
    "engine = sqlalchemy.create_engine(db_indv_coll)\n",
    "interpolations = pd.read_sql(\"ic2s2_interpolations\", con=engine)\n",
    "\n",
    "cnty = interpolations[\"cnty\"]\n",
    "diff_interpolated = interpolations[\"diff_interpolated\"]\n",
    "\n",
    "norm_cnty = []\n",
    "norm_diff_interpolated = []\n",
    "test = []\n",
    "for i in range(len(cnty)):\n",
    "    if(diff_interpolated[i] > 0 or diff_interpolated[i] <= 0):\n",
    "        norm_cnty.append(cnty[i])\n",
    "        norm_diff_interpolated.append(diff_interpolated[i])\n",
    "        test.append(1)\n",
    "norm_diff_interpolated = zero_one_normalize(norm_diff_interpolated)\n",
    "print(len(norm_diff_interpolated))\n",
    "normalized_diff = pd.DataFrame()\n",
    "normalized_diff[\"cnty\"] = norm_cnty\n",
    "normalized_diff[\"diff\"] = norm_diff_interpolated\n",
    "normalized_diff[\"test\"] = test\n",
    "\n",
    "normalized_diff.to_sql(\"ic2s2_interpolations_normalized\", con=engine, index=False, if_exists='replace', chunksize=50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042 1095\n",
      "1095 max:  6.249860840375836 min:  -3.022431632005638\n",
      "2042 max:  4.6184434211135335 min:  -5.39558067278122\n",
      "3137\n"
     ]
    }
   ],
   "source": [
    "county_df[\"diff\"] = zscore(county_df[\"collectivism\"]-county_df[\"individualism\"])\n",
    "diff = county_df[\"diff\"]\n",
    "reg_counties = county_df[\"cnty\"].values\n",
    "\n",
    "interpolations = pd.read_sql(\"ic2s2_interpolations\", con=engine)\n",
    "interpolations.dropna(inplace=True)\n",
    "interpolations = interpolations[~interpolations[\"cnty\"].isin(reg_counties)]\n",
    "diff_interpolated = zscore(interpolations[\"diff_interpolated\"])\n",
    "interpolations[\"diff_interpolated\"] = diff_interpolated\n",
    "interpolated_counties = interpolations[\"cnty\"].values\n",
    "\n",
    "print(len(reg_counties), len(interpolated_counties))\n",
    "print(len(diff_interpolated), \"max: \", max(diff_interpolated), \"min: \", min(diff_interpolated))\n",
    "print(len(diff), \"max: \", max(diff), \"min: \", min(diff))\n",
    "all_counties = list(set(list(reg_counties) + list(interpolated_counties)))\n",
    "print(len(all_counties))\n",
    "\n",
    "\n",
    "final_interpolations = pd.DataFrame()\n",
    "final_cnty = []\n",
    "final_diff = []\n",
    "added = 0\n",
    "for c in all_counties:\n",
    "    if(c in reg_counties):\n",
    "        final_cnty.append(c)\n",
    "        final_diff.append(county_df[county_df[\"cnty\"] == c][\"diff\"].values[0])\n",
    "        added += 1\n",
    "    elif(c in interpolated_counties):\n",
    "        final_cnty.append(c)\n",
    "        final_diff.append(interpolations[interpolations[\"cnty\"] == c][\"diff_interpolated\"].values[0])\n",
    "        added += 1\n",
    "    else:\n",
    "        continue\n",
    "final_interpolations[\"cnty\"] = final_cnty\n",
    "final_interpolations[\"diff\"] = final_diff\n",
    "final_interpolations.dropna(inplace=True)\n",
    "final_interpolations[\"diff\"] = zero_one_normalize(final_interpolations[\"diff\"])\n",
    "final_interpolations.to_sql(\"ic2s2_interpolations_final\", con=engine, index=False, if_exists='replace', chunksize=50000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_interpolations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shreya_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91463280d8781b4327168e6aed37b9922ec5e51ac75b06b77d3a30bc9c56392e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
